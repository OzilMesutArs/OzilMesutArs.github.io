{"meta":{"title":"OzilMesutArs's blog","subtitle":null,"description":null,"author":"OzilMesutArs","url":"http://OzilMesutArs.github.io","root":"/"},"pages":[{"title":"SQL","date":"2019-03-25T05:31:16.000Z","updated":"2019-03-26T04:37:38.831Z","comments":true,"path":"SQL/index.html","permalink":"http://OzilMesutArs.github.io/SQL/index.html","excerpt":"","text":"![1.png](https://github.com/OzilMesutArs/OzilMesutArs.github.io/tree/master/img/HDFS_Architecture/HDFS_Architecture.png"},{"title":"about","date":"2019-03-25T05:44:25.000Z","updated":"2019-03-25T05:44:25.356Z","comments":true,"path":"about/index.html","permalink":"http://OzilMesutArs.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"temp","date":"2019-03-27T10:54:51.219Z","updated":"2019-03-27T10:54:51.219Z","comments":true,"path":"2019/03/27/temp/","link":"","permalink":"http://OzilMesutArs.github.io/2019/03/27/temp/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"common node of LinkedList","slug":"commonNodeLL","date":"2019-03-25T05:23:20.000Z","updated":"2019-03-27T10:58:06.659Z","comments":true,"path":"2019/03/24/commonNodeLL/","link":"","permalink":"http://OzilMesutArs.github.io/2019/03/24/commonNodeLL/","excerpt":"","text":"","categories":[{"name":"Lintcode","slug":"Lintcode","permalink":"http://OzilMesutArs.github.io/categories/Lintcode/"}],"tags":[]},{"title":"ML simple Linear Regression","slug":"ml","date":"2019-03-25T05:23:20.000Z","updated":"2019-03-27T03:33:12.272Z","comments":true,"path":"2019/03/24/ml/","link":"","permalink":"http://OzilMesutArs.github.io/2019/03/24/ml/","excerpt":"","text":"线性回归 简单线性回归1.1 引言 上图中 样本特征是X轴，代表午饭价格，样本输出就是价格。 某点的样本特征表示为x^{(i)}其样本输出表示为 y^{(i)} 1.2 分类样本特征只有一个维度称为简单线性回归，样本特征是多个维度称为多元线性回归 1.3 简单线性回归的目的 在平面中找到这样一条直线，该直线可以拟合坐标系的点。 因为 直线方程为y=ax+b，我们将平面内的点带入直线方程可得出 \\hat{y}^{(i)}=ax^{(i)}+b在上式中, y的预测值就是\\hat{y} 所以现在目标就是寻找一条直线使得$\\hat{y}$与$\\hat{y}$之间的差距尽可能小 $\\hat{y}$与$y^{(i)}$差距的表示 可以使用$y^{(i)} - \\hat{y}^{(i)}$来表示二者之间的差距，但是其缺点是其结果有正有负，将所有点的差距叠加，有可能导致结果为0，显然不是我们想要的。 第二种方式是$\\left|y^{(i)}-\\hat{y}^{(i)}\\right|$, 但是绝对值不是处处可导的函数，所以也被放弃 第三种方式就是$\\left(y^{(i)}-\\hat{y}^{(i)}\\right)^2$, 该方式避免了上述的缺点。 现在目标变成将平面上所有的点带入第三种方式，所以函数变为\\sum_{i=1}^m\\left(y^{(i)}-\\hat{y}^{(i)}\\right)^2 新目标 我们现在目标变为找到a和b，使得$\\sum_{i=1}^m\\left(y^{(i)}-\\hat{y}^{(i)}\\right)^2$尽可能小，目前来说完成了建模过程(找到一个模型可以最大程度的拟合数据) 在简单线性回归中，该模型就是直线方程，最大程度拟合数据就是找到一个损失函数(loss function) 或者效用函数(utility function), 或者统称为目标函数(pbject function)。 根据直线方程，目标函数变成\\sum_{(i=1)}^m(y^{(i)}-ax^{(i)}-b)^2 如何优化 使用最小二乘法，可以处理最小化误差的平方的问题 此时a=\\frac{\\sum_{j=1}^m(x^{(i)}-\\bar{x})(y^{(i)}-\\bar{y}) } {\\sum_{(i=1)}^m(x^{(i)}-\\bar{x})^2} b=\\bar{y}-a\\bar{x} 最小二乘法 $\\sum_{(i=1)}^m(y^{(i)}-ax^{(i)}-b)^2$可以用J(a, b)表示目标现在是找到a和b, 使得J(a, b)尽可能小，J(a,b)表示参数为a和b的损失函数 求损失函数的最小值就是找到函数的极值, 所以J(a,b) 对参数a和b进行求导 \\frac{\\partial J(a,b)}{\\partial a} = 0\\frac{\\partial J(a,b)}{\\partial b} = 0所以$\\frac{\\partial J(a,b)}{\\partial b}=0$ $\\sum_{i=1}^m 2(y^{(i)}-ax^{(i)}-b)(-1)=0$$=&gt;\\sum_{i=1}^m (y^{(i)}-ax^{(i)}-b)=0$$=&gt;\\sum_{i=1}^my^{(i)} - a\\sum_{i=1}^m x^{(i)}-\\sum_{i=1}^mb = 0$$=&gt;\\sum_{i=1}^my^{(i)} - a\\sum_{i=1}^m x^{(i)}-mb=0$$=&gt;mb=\\sum_{i=1}^my^{(i)} - a\\sum_{i=1}^m x^{(i)}$(此时两边同时除以m, $\\sum_{i=1}^my^{(i)}$是所有y的和，除以m就是代表均值$\\bar{y}$, 对于另外一个式子同理。)所以$=&gt;b=\\bar{y}-a\\bar{x}$ 而对于$\\frac{\\partial J(a,b)}{\\partial a} = 0$$=&gt;\\sum_{i=1}^m 2(y^{(i)}-ax^{(i)}-b)(-x^{(i)})=0$$=&gt;\\sum_{i=1}^m (y^{(i)}-ax^{(i)}-b)x^{(i)}=0$(由于$b=\\bar{y}-a\\bar{x}$)所以$=&gt;\\sum_{i=1}^m (y^{(i)}-ax^{(i)}-\\bar{y}+a\\bar{x})x^{(i)}=0$($将x^{(i)}乘进括号内$)$=&gt;\\sum_{i=1}^m (x^{(i)}y^{(i)}-a(x^{(i)})^2-x^{(i)}\\bar{y}+a\\bar{x}x^{(i)})=0$$(整理一下可得到)$$=&gt;\\sum_{i=1}^m (x^{(i)}y^{(i)}-x^{(i)}\\bar{y}-a(x^{(i)})^2+a\\bar{x}x^{(i)})=0$$=&gt;\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y})-\\sum_{i=1}^m(a(x^{(i)})^2-a\\bar{x}x^{(i)})$$=&gt;\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y})-a\\sum_{i=1}^m((x^{(i)})^2-\\bar{x}x^{(i)})$所以$=&gt;a=\\frac{\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y})}{\\sum_{i=1}^m((x^{(i)})^2-\\bar{x}x^{(i)})}$ 又因为y的均值$\\bar{y}$是常数，所以$\\sum_{i=1}^mx^{(i)}\\bar{y}=\\bar{y}\\sum_{i=1}^mx^{(i)}$又因为 $\\frac{x^{(i)}}{m} = \\bar{x}$, 所以$\\sum_{i=1}^mx^{(i)}\\bar{y}=m\\bar{y}\\bar{x}$=$\\bar{x}\\sum_{i=1}^my^{(i)}$=$\\sum_{i=1}^my^{(i)}\\bar{x}$还因为$m\\bar{x}\\bar{y}$=$\\sum_{i=1}^m\\bar{x}\\bar{y}$ 所以$a=\\frac{\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y})}{\\sum_{i=1}^m((x^{(i)})^2-\\bar{x}x^{(i)})}$$=&gt;\\frac{\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y}-\\bar{x}y^{(i)}+\\bar{x}\\bar{y})}{\\sum_{i=1}^m((x^{(i)})^2-\\bar{x}x^{(i)}-\\bar{x}x^{(i)}+\\bar{x}^2)}$$=&gt;\\frac{\\sum_{i=1}^m(x^{(i)}-\\bar{x})(y^{(i)}-\\bar{y})}{\\sum_{i=1}^m(x^{(i)}-\\bar{x})^2}$","categories":[{"name":"ML","slug":"ML","permalink":"http://OzilMesutArs.github.io/categories/ML/"}],"tags":[]},{"title":"HDFS","slug":"sql","date":"2019-03-25T05:23:20.000Z","updated":"2019-03-28T03:13:21.473Z","comments":true,"path":"2019/03/24/sql/","link":"","permalink":"http://OzilMesutArs.github.io/2019/03/24/sql/","excerpt":"","text":"HDFS使用主从架构 12345其中分为三部分NN、SNN、DNNN是主节点，也叫名称节点 SNN在主节点挂了之后起作用，也叫第二名称节点DN是从，也叫数据节点 1注: 其中圆形代表数据块1，菱形代表数据块2 1.1 NameNode1(1) NN代表文件系统的命名空间 1234567(2) 存储内容 a. 文件名称 b. 文件目录结构 c. 文件属性(包括创建时间、权限、副本数) d. blockmap: 文件对应的数据块与数据块分布的datanode节点一一映射关系 注: namenode不会持久化存储这种映射关系 主要靠datanode定期发送blockreport给master说明机器上存储了哪些数据块的副本，master接收信息后定期更新存储关系 12345(3) NameNode主要维护的是文件的目录系统(文件系统树)，以两种文件永久保存在磁盘 &#123; fsimage &lt;==&gt; 命名空间镜像文件, edit &lt;==&gt; 编辑日志 &#125; 1.2 DataNode 123(1) 存储数据块和块的checksum a. 当某一个副本的checksum不对，会复制其他的副本 b. 如果所有副本都错误，会在50070的web界面显示出来 12345(2)与NN通信: a. 每隔3秒向master发送心跳包 b. 每10次发送一个blockreport(3) 主要用途 a. 文件数据块的读写 1.3 SNN1(1)SNN存储的内容: fsimage + editlog 1(2)作用: 定期合并fsimage + editlog为新的fsimage并推送给NN，该文件被称作checkpoint","categories":[{"name":"HDFS","slug":"HDFS","permalink":"http://OzilMesutArs.github.io/categories/HDFS/"}],"tags":[]},{"title":"","slug":"henry","date":"2019-03-25T04:55:03.333Z","updated":"2019-03-25T04:55:03.333Z","comments":true,"path":"2019/03/24/henry/","link":"","permalink":"http://OzilMesutArs.github.io/2019/03/24/henry/","excerpt":"","text":"123public static void main(String[] args)&#123; System.out.println(\"hh\");&#125;","categories":[],"tags":[]},{"title":"MapReduce","slug":"mr","date":"2019-01-05T18:11:01.000Z","updated":"2019-03-28T07:32:26.483Z","comments":true,"path":"2019/01/05/mr/","link":"","permalink":"http://OzilMesutArs.github.io/2019/01/05/mr/","excerpt":"","text":"1.MapReduce含义 1MapReduce指两个函数, 分别是Map函数和Reduce函数 1.1 Map函数1234Map函数被称为映射 过程: String ==&gt; (key, value)映射的个数不会变，只是将其变成另一种形式 12Example: abc ==&gt; (abc, 1) 1.2 Reduce函数12Reduce函数被称为规约 将属于相同key的(key, value)进行合并 1234Example: (abc, 1) (abc, 1) ==&gt; (abc, 1+1+1) (abc, 1) 2.MapReduce流程 2.1 MapReduce流程图 2.2 shuffling (1) 所处位置1在map与reduce之间 (2) shuffling的意义123shuffling就是将相同key的(key, value)放到一起从mapping到shuffling的过程中, IO是杂乱无序的, 和洗牌类似","categories":[{"name":"MapReduce","slug":"MapReduce","permalink":"http://OzilMesutArs.github.io/categories/MapReduce/"}],"tags":[]},{"title":"HDFS写流程","slug":"hdfsWrite","date":"2019-01-04T18:11:01.000Z","updated":"2019-03-28T06:02:17.373Z","comments":true,"path":"2019/01/04/hdfsWrite/","link":"","permalink":"http://OzilMesutArs.github.io/2019/01/04/hdfsWrite/","excerpt":"","text":"1.写操作的职责1将存储在linux上的文件放入HDFS上 2.写操作具体流程1(1) client 调用Distributed file system的create方法, 其参数就是文件夹路径path, dfs.create(path) 123456(2) 与NN进行RPC通信, 检查该path是否存在&amp;&amp;检查是否有权限创建文件 if(检查成功): 根据路径创建一个新文件，但不关联任何的block(意味着是空文件) return FSDataOutputStream对象 else: 返回相应的错误信息 12345(3) client调用FSDataOutputStream对象的write方法将第一个块写给DN1, DN1复制block给DN2, DN2复制block给DN3 都写完后, DN3返回ack给DN2, DN2收到ack packet返回ack给DN1, DN1收到ack packet返回ack给FSOutputStream对象 到此标志一个block的3个replica全部写完 1(4) 当文件内容全部写完, client调用FSDataOutputStream的close()方法, 关闭输出流, flush缓存区的数据包 1(5)调用Distributed file system的complete()方法, 告诉NN已经全部写完 3.注意事项1写操作使用的是OutputStream","categories":[{"name":"HDFS","slug":"HDFS","permalink":"http://OzilMesutArs.github.io/categories/HDFS/"}],"tags":[]},{"title":"HDFS副本放置策略","slug":"storeStrategy","date":"2019-01-03T20:12:33.000Z","updated":"2019-03-28T05:04:09.047Z","comments":true,"path":"2019/01/03/storeStrategy/","link":"","permalink":"http://OzilMesutArs.github.io/2019/01/03/storeStrategy/","excerpt":"","text":"1.blocksize与副本数的设置 1.1 配置参数 1在hdfs-site中配置 参数名 默认值 描述 dfs.blocksize 134217728(128M) The default block size for new files, in bytes dfs.replication 3 Default block replication 1.2 block数计算1eg. 如果一个文件260M, 该文件会占据3个block, 分别是2个128M的block，和一个4M的block 2.机架示意图 3.副本放置策略 3.1 第一个副本放置策略123假设客户端提交文件所在机器就是datanode节点, 那么第一个块就在该datanode节点上如果不是就存储在磁盘not full, cpu not busy的节点上(通过NN发现的) 3.2 其他副本的放置策略 123456如果只有一个机架: 其他副本存放在于不保存第一个副本的机器上如果有多个机架 第二个副本存放于不同机架上的任意机器上 第三个副本存放于第二个副本所在的机架不同的机器上","categories":[{"name":"HDFS","slug":"HDFS","permalink":"http://OzilMesutArs.github.io/categories/HDFS/"}],"tags":[]},{"title":"fsimage和editlog","slug":"editlog","date":"2019-01-03T06:23:20.000Z","updated":"2019-03-28T03:17:08.330Z","comments":true,"path":"2019/01/02/editlog/","link":"","permalink":"http://OzilMesutArs.github.io/2019/01/02/editlog/","excerpt":"","text":"1.fsimage和editlog的含义1fsimage: 镜像文件, 代表某一时间系统的文件系统树 1editlog: 操作日志, 代表从该时间点之后的操作 2.生成新的fsimage的流程 2.1 为什么要生成新的faimage1防止editlog过大 2.2 生成新的fsimage和editlog的流程12345678a. 当checkpoint时间到时，SNN将NN的fsimage和ediitlog拉取过来并将其合并为一个新的fsimage 当到达检查点时, 会生成新的editlog文件, 之后所进行的操作都写在新的editlog中 (如果到达下次checkpoint前操作比较频繁，editlog不一定只有一个，可能会有多个) b. SNN将新生成的fsimage传给NNc. 新的fsimage就是checkpoint后的fsimage, 新的editlogs就变成editlogs 3.如何设定checkpoint时间间隔 3.1 设置于哪个文件1hdfs-sit.xml 3.2 参数简介 参数名 默认值 描述 dfs.namenode.checkpoint.period 3600 The number of seconds between two periodic checkpoints 3.3 Example1假设NN运行了25小时13分钟, SNN每过一小时就将NN的fsimage和editlog文件合并生成新的fsimage, 但是如果此时NN发生问题, SNN只能将其恢复到运行第25小时的状态","categories":[{"name":"HDFS","slug":"HDFS","permalink":"http://OzilMesutArs.github.io/categories/HDFS/"}],"tags":[]}]}