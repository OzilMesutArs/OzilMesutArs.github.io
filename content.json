{"meta":{"title":"OzilMesutArs's blog","subtitle":null,"description":null,"author":"OzilMesutArs","url":"http://OzilMesutArs.github.io","root":"/"},"pages":[{"title":"SQL","date":"2019-03-25T05:31:16.000Z","updated":"2019-03-26T04:37:38.831Z","comments":true,"path":"SQL/index.html","permalink":"http://OzilMesutArs.github.io/SQL/index.html","excerpt":"","text":"![1.png](https://github.com/OzilMesutArs/OzilMesutArs.github.io/tree/master/img/HDFS_Architecture/HDFS_Architecture.png"},{"title":"about","date":"2019-03-25T05:44:25.000Z","updated":"2019-03-25T05:44:25.356Z","comments":true,"path":"about/index.html","permalink":"http://OzilMesutArs.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"HDFS","slug":"ml","date":"2019-03-25T05:23:20.000Z","updated":"2019-03-27T03:27:36.989Z","comments":true,"path":"2019/03/24/ml/","link":"","permalink":"http://OzilMesutArs.github.io/2019/03/24/ml/","excerpt":"","text":"线性回归 简单线性回归1.1 引言 上图中 样本特征是X轴，代表午饭价格，样本输出就是价格。 某点的样本特征表示为x^{(i)}其样本输出表示为 y^{(i)} 1.2 分类样本特征只有一个维度称为简单线性回归，样本特征是多个维度称为多元线性回归 1.3 简单线性回归的目的 在平面中找到这样一条直线，该直线可以拟合坐标系的点。 因为 直线方程为y=ax+b，我们将平面内的点带入直线方程可得出 \\hat{y}^{(i)}=ax^{(i)}+b在上式中, y的预测值就是\\hat{y} 所以现在目标就是寻找一条直线使得$\\hat{y}$与$\\hat{y}$之间的差距尽可能小 $\\hat{y}$与$y^{(i)}$差距的表示 可以使用$y^{(i)} - \\hat{y}^{(i)}$来表示二者之间的差距，但是其缺点是其结果有正有负，将所有点的差距叠加，有可能导致结果为0，显然不是我们想要的。 第二种方式是$\\left|y^{(i)}-\\hat{y}^{(i)}\\right|$, 但是绝对值不是处处可导的函数，所以也被放弃 第三种方式就是$\\left(y^{(i)}-\\hat{y}^{(i)}\\right)^2$, 该方式避免了上述的缺点。 现在目标变成将平面上所有的点带入第三种方式，所以函数变为\\sum_{i=1}^m\\left(y^{(i)}-\\hat{y}^{(i)}\\right)^2 新目标 我们现在目标变为找到a和b，使得$\\sum_{i=1}^m\\left(y^{(i)}-\\hat{y}^{(i)}\\right)^2$尽可能小，目前来说完成了建模过程(找到一个模型可以最大程度的拟合数据) 在简单线性回归中，该模型就是直线方程，最大程度拟合数据就是找到一个损失函数(loss function) 或者效用函数(utility function), 或者统称为目标函数(pbject function)。 根据直线方程，目标函数变成\\sum_{(i=1)}^m(y^{(i)}-ax^{(i)}-b)^2 如何优化 使用最小二乘法，可以处理最小化误差的平方的问题 此时a=\\frac{\\sum_{j=1}^m(x^{(i)}-\\bar{x})(y^{(i)}-\\bar{y}) } {\\sum_{(i=1)}^m(x^{(i)}-\\bar{x})^2} b=\\bar{y}-a\\bar{x} 最小二乘法 $\\sum_{(i=1)}^m(y^{(i)}-ax^{(i)}-b)^2$可以用J(a, b)表示目标现在是找到a和b, 使得J(a, b)尽可能小，J(a,b)表示参数为a和b的损失函数 求损失函数的最小值就是找到函数的极值, 所以J(a,b) 对参数a和b进行求导 \\frac{\\partial J(a,b)}{\\partial a} = 0\\frac{\\partial J(a,b)}{\\partial b} = 0所以$\\frac{\\partial J(a,b)}{\\partial b}=0$ $\\sum_{i=1}^m 2(y^{(i)}-ax^{(i)}-b)(-1)=0$$=&gt;\\sum_{i=1}^m (y^{(i)}-ax^{(i)}-b)=0$$=&gt;\\sum_{i=1}^my^{(i)} - a\\sum_{i=1}^m x^{(i)}-\\sum_{i=1}^mb = 0$$=&gt;\\sum_{i=1}^my^{(i)} - a\\sum_{i=1}^m x^{(i)}-mb=0$$=&gt;mb=\\sum_{i=1}^my^{(i)} - a\\sum_{i=1}^m x^{(i)}$(此时两边同时除以m, $\\sum_{i=1}^my^{(i)}$是所有y的和，除以m就是代表均值$\\bar{y}$, 对于另外一个式子同理。)所以$=&gt;b=\\bar{y}-a\\bar{x}$ 而对于$\\frac{\\partial J(a,b)}{\\partial a} = 0$$=&gt;\\sum_{i=1}^m 2(y^{(i)}-ax^{(i)}-b)(-x^{(i)})=0$$=&gt;\\sum_{i=1}^m (y^{(i)}-ax^{(i)}-b)x^{(i)}=0$(由于$b=\\bar{y}-a\\bar{x}$)所以$=&gt;\\sum_{i=1}^m (y^{(i)}-ax^{(i)}-\\bar{y}+a\\bar{x})x^{(i)}=0$($将x^{(i)}乘进括号内$)$=&gt;\\sum_{i=1}^m (x^{(i)}y^{(i)}-a(x^{(i)})^2-x^{(i)}\\bar{y}+a\\bar{x}x^{(i)})=0$$(整理一下可得到)$$=&gt;\\sum_{i=1}^m (x^{(i)}y^{(i)}-x^{(i)}\\bar{y}-a(x^{(i)})^2+a\\bar{x}x^{(i)})=0$$=&gt;\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y})-\\sum_{i=1}^m(a(x^{(i)})^2-a\\bar{x}x^{(i)})$$=&gt;\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y})-a\\sum_{i=1}^m((x^{(i)})^2-\\bar{x}x^{(i)})$所以$=&gt;a=\\frac{\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y})}{\\sum_{i=1}^m((x^{(i)})^2-\\bar{x}x^{(i)})}$ 又因为y的均值$\\bar{y}$是常数，所以$\\sum_{i=1}^mx^{(i)}\\bar{y}=\\bar{y}\\sum_{i=1}^mx^{(i)}$又因为 $\\frac{x^{(i)}}{m} = \\bar{x}$, 所以$\\sum_{i=1}^mx^{(i)}\\bar{y}=m\\bar{y}\\bar{x}$=$\\bar{x}\\sum_{i=1}^my^{(i)}$=$\\sum_{i=1}^my^{(i)}\\bar{x}$还因为$m\\bar{x}\\bar{y}$=$\\sum_{i=1}^m\\bar{x}\\bar{y}$ 所以$a=\\frac{\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y})}{\\sum_{i=1}^m((x^{(i)})^2-\\bar{x}x^{(i)})}$$=&gt;\\frac{\\sum_{i=1}^m(x^{(i)}y^{(i)}-x^{(i)}\\bar{y}-\\bar{x}y^{(i)}+\\bar{x}\\bar{y})}{\\sum_{i=1}^m((x^{(i)})^2-\\bar{x}x^{(i)}-\\bar{x}x^{(i)}+\\bar{x}^2)}$$=&gt;\\frac{\\sum_{i=1}^m(x^{(i)}-\\bar{x})(y^{(i)}-\\bar{y})}{\\sum_{i=1}^m(x^{(i)}-\\bar{x})^2}$","categories":[{"name":"HDFS","slug":"HDFS","permalink":"http://OzilMesutArs.github.io/categories/HDFS/"}],"tags":[]},{"title":"HDFS","slug":"sql","date":"2019-03-25T05:23:20.000Z","updated":"2019-03-26T11:57:11.769Z","comments":true,"path":"2019/03/24/sql/","link":"","permalink":"http://OzilMesutArs.github.io/2019/03/24/sql/","excerpt":"","text":"HDFS使用主从架构 12345其中分为三部分NN、SNN、DNNN是主节点，也叫名称节点 SNN在主节点挂了之后起作用，也叫第二名称节点DN是从，也叫数据节点 1注: 其中圆形代表数据块1，菱形代表数据块2 1.1 NameNode1(1) NN代表文件系统的命名空间 1234567(2) 存储内容 a. 文件名称 b. 文件目录结构 c. 文件属性(包括创建时间、权限、副本数) d. blockmap: 文件对应的数据块与数据块分布的datanode节点一一映射关系 注: namenode不会持久化存储这种映射关系 主要靠datanode定期发送blockreport给master说明机器上存储了哪些数据块的副本，master接收信息后定期更新存储关系 12345(3) NameNode主要维护的是文件的目录系统(文件系统树)，以两种文件永久保存在磁盘 &#123; fsimage &lt;==&gt; 命名空间镜像文件, edit &lt;==&gt; 编辑日志 &#125; 1.2 DataNode 123(1) 存储数据块和块的checksum a. 当某一个副本的checksum不对，会复制其他的副本 b. 如果所有副本都错误，会在50070的web界面显示出来 12345(2)与NN通信: a. 每隔3秒向master发送心跳包 b. 每10次发送一个blockreport(3) 主要用途 a. 文件数据块的读写 1.3 SNN1(1)SNN存储的内容: fsimage + editlog 1(2)作用: 定期合并fsimage + editlog为新的fsimage并推送给NN，该文件被称作checkpoint $x^y$","categories":[{"name":"HDFS","slug":"HDFS","permalink":"http://OzilMesutArs.github.io/categories/HDFS/"}],"tags":[]},{"title":"","slug":"henry","date":"2019-03-25T04:55:03.333Z","updated":"2019-03-25T04:55:03.333Z","comments":true,"path":"2019/03/24/henry/","link":"","permalink":"http://OzilMesutArs.github.io/2019/03/24/henry/","excerpt":"","text":"123public static void main(String[] args)&#123; System.out.println(\"hh\");&#125;","categories":[],"tags":[]}]}